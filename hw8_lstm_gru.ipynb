{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bf6f873",
      "metadata": {
        "id": "1bf6f873"
      },
      "source": [
        "# Домашнее задание № 8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4bd487",
      "metadata": {
        "id": "3b4bd487"
      },
      "source": [
        "## Задание 1 (4 балла) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4c4f87",
      "metadata": {
        "id": "bf4c4f87"
      },
      "source": [
        "Обучите 7 моделей для задачи классификации текста (датасет - lenta_40k ). А именно:  \n",
        "1) модель с 1 GRU слоем;   \n",
        "2) модель с 1 LSTM слоем    \n",
        "3) модель с 1 GRU и 1 LSTM слоем  \n",
        "4) модель с 1 BIGRU и 2 LSTM слоями  \n",
        "5) модель с 5 GRU слоями и 3 LSTM слоями  \n",
        "6) модель 1 BIGRU и 1 BILSTM слоями, причем так чтобы модели для forward и backward прохода отличались   \n",
        "7) модель, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM  \n",
        "\n",
        "\n",
        "\n",
        "Параметр units и размер эмбединга можете задать любой. Оцените качество каждой модели и определите победителя."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "-pfFRAAqK5fi"
      },
      "id": "-pfFRAAqK5fi",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83db6635",
      "metadata": {
        "id": "83db6635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1d886b-820a-43b6-99d1-e1b394840545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50362f6e",
      "metadata": {
        "id": "50362f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368d2026-ae12-446e-e13f-1d8657eba7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считываем данные — новостные тексты с lenta.ru"
      ],
      "metadata": {
        "id": "K3itK3DrLaF9"
      },
      "id": "K3itK3DrLaF9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6676dab",
      "metadata": {
        "id": "b6676dab"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('lenta_40k.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для простой предобработки"
      ],
      "metadata": {
        "id": "UTHdv03nLoEF"
      },
      "id": "UTHdv03nLoEF"
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [token.strip(punctuation) for token in tokens]\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "6k2ALwptLmfA"
      },
      "id": "6k2ALwptLmfA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для рассчета f-меры в TensorFlow (источник: stackoverflow)"
      ],
      "metadata": {
        "id": "8O_pTfbSLk9V"
      },
      "id": "8O_pTfbSLk9V"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "metadata": {
        "id": "qTutqSTjMVP9"
      },
      "id": "qTutqSTjMVP9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем словарь и фильтруем его, оставляя только частотные слова\n"
      ],
      "metadata": {
        "id": "VDlcQS2lMc5T"
      },
      "id": "VDlcQS2lMc5T"
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for text in data.text:\n",
        "    vocab.update(preprocess(text))"
      ],
      "metadata": {
        "id": "IjrG-m5xMYSK"
      },
      "id": "IjrG-m5xMYSK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставим в словаре слова, которые встретились в корпусе не менее 30 раз"
      ],
      "metadata": {
        "id": "mX35CDGhNVaI"
      },
      "id": "mX35CDGhNVaI"
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_vocab = set()\n",
        "\n",
        "for word in vocab:\n",
        "    if vocab[word] > 30: \n",
        "        filtered_vocab.add(word)"
      ],
      "metadata": {
        "id": "nrLgCSerNMzJ"
      },
      "id": "nrLgCSerNMzJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим словари для перевода слов в индексы и наоборот"
      ],
      "metadata": {
        "id": "Qroz2jA9Nvsa"
      },
      "id": "Qroz2jA9Nvsa"
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {'PAD':0, 'UNK':1}\n",
        "\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)"
      ],
      "metadata": {
        "id": "FkaIDOI-N0Xy"
      },
      "id": "FkaIDOI-N0Xy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "metadata": {
        "id": "JG7HS1E4N2lI"
      },
      "id": "JG7HS1E4N2lI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "\n",
        "for text in data.text:\n",
        "    tokens = preprocess(text)\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)"
      ],
      "metadata": {
        "id": "Cpcc-SA0N275"
      },
      "id": "Cpcc-SA0N275",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padding\n",
        "\n",
        "MAX_LEN = max(len(x) for x in X)\n",
        "MEAN_LEN = np.median([len(x) for x in X])\n",
        "MAX_LEN = int(MEAN_LEN + 30)\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)"
      ],
      "metadata": {
        "id": "e_vZAN7COZHw"
      },
      "id": "e_vZAN7COZHw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9hOb43LQXOG",
        "outputId": "343ed2b7-4eea-408e-84b1-370d7b7be7e8"
      },
      "id": "-9hOb43LQXOG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44356, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
        "label2id = {l:i for i, l in id2label.items()}"
      ],
      "metadata": {
        "id": "FDCnbsp8Q9oV"
      },
      "id": "FDCnbsp8Q9oV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])"
      ],
      "metadata": {
        "id": "UMvAJsARQ_ea"
      },
      "id": "UMvAJsARQ_ea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим стратификацию, т.к. в данных дисбаланс классов"
      ],
      "metadata": {
        "id": "F6C7dUEMRA6x"
      },
      "id": "F6C7dUEMRA6x"
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y)"
      ],
      "metadata": {
        "id": "kmE0qtYcRIEv"
      },
      "id": "kmE0qtYcRIEv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "rmxcAy2AU_KD"
      },
      "id": "rmxcAy2AU_KD"
    },
    {
      "cell_type": "code",
      "source": [
        "scores = {} "
      ],
      "metadata": {
        "id": "3yy58T8xr2ro"
      },
      "id": "3yy58T8xr2ro",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 1: модель с 1 GRU слоем\n"
      ],
      "metadata": {
        "id": "hxTabCjtpluP"
      },
      "id": "hxTabCjtpluP"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "gru_layer = tf.keras.layers.GRU(128, return_sequences=False)(embeddings)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(gru_layer)\n",
        "\n",
        "model_1 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_1.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "metadata": {
        "id": "9DrU5Bc9plJ_"
      },
      "id": "9DrU5Bc9plJ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "xmMdWI-lsVrd"
      },
      "id": "xmMdWI-lsVrd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "NDJEB8RisWGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc0c8e5-24ae-4623-c195-f4264804e71b"
      },
      "id": "NDJEB8RisWGu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.946437418460846"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['1 GRU слой'] = model_1.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "KaWrXi95sZKf"
      },
      "id": "KaWrXi95sZKf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 2: модель с 1 LSTM слоем\n"
      ],
      "metadata": {
        "id": "oTJ33aSvVLWC"
      },
      "id": "oTJ33aSvVLWC"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "lstm_layer = tf.keras.layers.LSTM(128, return_sequences=False)(embeddings)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(lstm_layer)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_2.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "metadata": {
        "id": "e_8uGWQnVujL"
      },
      "id": "e_8uGWQnVujL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "UUXSor2MWEh_"
      },
      "id": "UUXSor2MWEh_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.history.history['f1'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccl8fKNHXI2r",
        "outputId": "e2b32a97-3a9a-4564-a957-9e045688b788"
      },
      "id": "ccl8fKNHXI2r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9168779850006104"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['1 LSTM слой'] = model_2.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "SISyFEUIsj4u"
      },
      "id": "SISyFEUIsj4u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 3: модель с 1 GRU и 1 LSTM слоем"
      ],
      "metadata": {
        "id": "pMTk93RFszsg"
      },
      "id": "pMTk93RFszsg"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(embeddings)\n",
        "lstm_2 = tf.keras.layers.GRU(128, return_sequences=False)(lstm_1)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_2)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_3.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])\n"
      ],
      "metadata": {
        "id": "PtL4kqtLtEVT"
      },
      "id": "PtL4kqtLtEVT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "Zp1uDZRttwp0"
      },
      "id": "Zp1uDZRttwp0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "KygLorEhtzAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c6d959-82c2-4104-bd7d-b5c8507b597f"
      },
      "id": "KygLorEhtzAw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9580317735671997"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['1 GRU и 1 LSTM слой'] = model_3.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "dqUdYDebt098"
      },
      "id": "dqUdYDebt098",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 4: модель с 1 BiGRU и 2 LSTM слоями"
      ],
      "metadata": {
        "id": "-MXd4i9AuKWS"
      },
      "id": "-MXd4i9AuKWS"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "bigru_layer = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(embeddings)\n",
        "lstm_layer_1 = tf.keras.layers.LSTM(128, return_sequences=True)(bigru_layer)\n",
        "lstm_layer_2 = tf.keras.layers.LSTM(128, return_sequences=False)(lstm_layer_1)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_layer_2)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_4 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_4.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "metadata": {
        "id": "33oANH14uJtc"
      },
      "id": "33oANH14uJtc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "5ZpNjaY88Nfu"
      },
      "id": "5ZpNjaY88Nfu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.history.history['f1'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwrn-YZH821u",
        "outputId": "c13c570f-4749-4644-8d8e-651f2a7db333"
      },
      "id": "Cwrn-YZH821u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9138382077217102"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['1 BiGRU и 2 LSTM слоя'] = model_4.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "MmVNVhGF845h"
      },
      "id": "MmVNVhGF845h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 5: модель с 5 GRU и 3 LSTM слоями"
      ],
      "metadata": {
        "id": "ZUag53Ev9gAN"
      },
      "id": "ZUag53Ev9gAN"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "# 5 GRU слоев\n",
        "gru_1 = tf.keras.layers.GRU(128, return_sequences=True)(embeddings)\n",
        "gru_2 = tf.keras.layers.GRU(128, return_sequences=True)(gru_1)\n",
        "gru_3 = tf.keras.layers.GRU(128, return_sequences=True)(gru_2)\n",
        "gru_4 = tf.keras.layers.GRU(128, return_sequences=True)(gru_3)\n",
        "gru_5 = tf.keras.layers.GRU(128, return_sequences=True)(gru_4)\n",
        "\n",
        "# 3 LSTM слоя\n",
        "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(gru_5)\n",
        "lstm_2 = tf.keras.layers.LSTM(128, return_sequences=True)(lstm_1)\n",
        "lstm_3 = tf.keras.layers.LSTM(128, return_sequences=False)(lstm_2)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_3)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_5.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "metadata": {
        "id": "I9tyJKu_-tFL"
      },
      "id": "I9tyJKu_-tFL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "787jcLGW_q9B"
      },
      "id": "787jcLGW_q9B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.history.history['f1'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jk5xS9U_uTR",
        "outputId": "5eb0fa2a-dc67-4ac5-c4a1-ee9e1656a7e6"
      },
      "id": "9Jk5xS9U_uTR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6030071973800659"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['5 GRU и 3 LSTM слоя'] = model_5.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "txBUC4aN_wD2"
      },
      "id": "txBUC4aN_wD2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 6: модель с 1 BIGRU и 1 BILSTM слоями (причем так, чтобы модели для forward и backward прохода отличались)"
      ],
      "metadata": {
        "id": "CQ7pCKQzARqA"
      },
      "id": "CQ7pCKQzARqA"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "bigru_bilstm = tf.keras.layers.Bidirectional(\n",
        "                                       tf.keras.layers.GRU(128, return_sequences=False),\n",
        "                        backward_layer=tf.keras.layers.LSTM(128, return_sequences=False, \n",
        "                                                            go_backwards=True))(embeddings)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(bigru_bilstm)\n",
        "model_6 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model_6.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "metadata": {
        "id": "rcIQ2P74BzSB"
      },
      "id": "rcIQ2P74BzSB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "gnA1tuYYEWCU"
      },
      "id": "gnA1tuYYEWCU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.history.history['f1'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeXl0Cl2ChPZ",
        "outputId": "c978f583-aff7-482e-ebd6-1f927d5d14b6"
      },
      "id": "eeXl0Cl2ChPZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7875635623931885"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['1 BiGRU и 1 BiLSTM'] = model_6.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "3JHORNm5CjZ4"
      },
      "id": "3JHORNm5CjZ4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model 7. Модель с последовательностью слоев: LSTM, GRU, BiLSTM, BiGRU, GRU, LSTM"
      ],
      "metadata": {
        "id": "j-htL5qrC-C1"
      },
      "id": "j-htL5qrC-C1"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(embeddings)\n",
        "gru_1 = tf.keras.layers.GRU(128, return_sequences=True)(lstm_1)\n",
        "bilstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(gru_1)\n",
        "bigru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(bilstm)\n",
        "gru_2 = tf.keras.layers.GRU(128, return_sequences=True)(bigru)\n",
        "lstm_2_final = tf.keras.layers.LSTM(128, return_sequences=False)(gru_2)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_2_final)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_7 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model_7.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "metadata": {
        "id": "m4_szWt3DVIG"
      },
      "id": "m4_szWt3DVIG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "JS1CkQUwEUEr"
      },
      "id": "JS1CkQUwEUEr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_7.history.history['f1'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY7-g5-6EbTt",
        "outputId": "93e8fac0-8421-47fb-d9d4-ded85540b18b"
      },
      "id": "NY7-g5-6EbTt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8944259285926819"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores['LSTM, GRU, BiLSTM, BiGRU, GRU, LSTM'] = model_7.history.history['f1'][-1]"
      ],
      "metadata": {
        "id": "v4Sl5STwEc77"
      },
      "id": "v4Sl5STwEc77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Оценка качества моделей, выбор лучшей модели"
      ],
      "metadata": {
        "id": "KIJvYe17FIML"
      },
      "id": "KIJvYe17FIML"
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df = pd.DataFrame.from_dict(scores, orient='index', columns=['f-score'])"
      ],
      "metadata": {
        "id": "_Yyr8R8lFPq4"
      },
      "id": "_Yyr8R8lFPq4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores_df.sort_values(by=['f-score'], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "YgODVPQ3FaSi",
        "outputId": "26421ab8-1d38-4be6-906e-2eed0101aca1"
      },
      "id": "YgODVPQ3FaSi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      f-score\n",
              "1 GRU и 1 LSTM слой                  0.958032\n",
              "1 GRU слой                           0.946437\n",
              "1 LSTM слой                          0.916878\n",
              "1 BiGRU и 2 LSTM слоя                0.913838\n",
              "LSTM, GRU, BiLSTM, BiGRU, GRU, LSTM  0.894426\n",
              "1 BiGRU и 1 BiLSTM                   0.787564\n",
              "5 GRU и 3 LSTM слоя                  0.603007"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68319777-9d99-45c8-9624-4921d8c82cae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>f-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1 GRU и 1 LSTM слой</th>\n",
              "      <td>0.958032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1 GRU слой</th>\n",
              "      <td>0.946437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1 LSTM слой</th>\n",
              "      <td>0.916878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1 BiGRU и 2 LSTM слоя</th>\n",
              "      <td>0.913838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM, GRU, BiLSTM, BiGRU, GRU, LSTM</th>\n",
              "      <td>0.894426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1 BiGRU и 1 BiLSTM</th>\n",
              "      <td>0.787564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5 GRU и 3 LSTM слоя</th>\n",
              "      <td>0.603007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68319777-9d99-45c8-9624-4921d8c82cae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68319777-9d99-45c8-9624-4921d8c82cae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68319777-9d99-45c8-9624-4921d8c82cae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В итоге, лучший результат в данной серии экспериментов был получен моделью с 1 GRU и 1 LSTM слоями. Не менее хорошие результаты показали модели, где использовалось по одному RNN слою: на втором месте модель с 1 GRU слоем, на третьем — модель с 1 LSTM слоем. Усложнение архитектуры модели в данном эксперименте не привело к улучшению качества результатов. Худшей оказалась модель с 5 GRU и 3 LSTM слоями."
      ],
      "metadata": {
        "id": "cbs2uoo4R2Zk"
      },
      "id": "cbs2uoo4R2Zk"
    },
    {
      "cell_type": "markdown",
      "id": "ed5d6eea",
      "metadata": {
        "id": "ed5d6eea"
      },
      "source": [
        "## Задание 2 (6 баллов)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c2c07cf",
      "metadata": {
        "id": "5c2c07cf"
      },
      "source": [
        "На данных википедии (wikiann) обучите 2 модели:  \n",
        "1) модель в которой будут использованы предобученные эмбединги слов и несколько BILSTM слоев. \n",
        "1) модель в которой будут использованы предобученные эмбединги слов и несколько BIGRU слоев. \n",
        "\n",
        "Сравните качество по метрикам. Также придумайте несколько сложных примеров и проверьте, какие сущности определяет каждая из моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим датасет wikiann\n"
      ],
      "metadata": {
        "id": "1Pa0hxTFJ4DT"
      },
      "id": "1Pa0hxTFJ4DT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb704b1b",
      "metadata": {
        "id": "fb704b1b"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b4e4aa",
      "metadata": {
        "id": "24b4e4aa"
      },
      "outputs": [],
      "source": [
        "wikiann_dataset = load_dataset(\"wikiann\", 'ru')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим словарь и проиндексируем его"
      ],
      "metadata": {
        "id": "_Q68MjCjKfYX"
      },
      "id": "_Q68MjCjKfYX"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8035db14",
      "metadata": {
        "id": "8035db14"
      },
      "outputs": [],
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for sent in wikiann_dataset['train']['tokens']:\n",
        "    vocab.update([x.lower() for x in sent])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = {'PAD':0, 'UNK':1}\n",
        "\n",
        "for word in vocab:\n",
        "    word2id[word] = len(word2id)"
      ],
      "metadata": {
        "id": "gRi6_z9WKmnw"
      },
      "id": "gRi6_z9WKmnw",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "metadata": {
        "id": "SzXcWQgdKoGw"
      },
      "id": "SzXcWQgdKoGw",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "\n",
        "for sent in wikiann_dataset['train']['tokens']:\n",
        "    tokens = [w.lower() for w in sent]\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)"
      ],
      "metadata": {
        "id": "TjVBaRTCKoL1"
      },
      "id": "TjVBaRTCKoL1",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = [] # тесты\n",
        "\n",
        "for sent in wikiann_dataset['test']['tokens']:\n",
        "    tokens = [w.lower() for w in sent]\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X_test.append(ids)"
      ],
      "metadata": {
        "id": "qohWIAXMKxD5"
      },
      "id": "qohWIAXMKxD5",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = max(len(x) for x in X)\n",
        "\n",
        "# padding\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN, padding='post')\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=MAX_LEN, padding='post')"
      ],
      "metadata": {
        "id": "PTxNpEXxK2n2"
      },
      "id": "PTxNpEXxK2n2",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обратный маппинг\n",
        "id2labels = {0:'O', 1:'B-PER', 2:'I-PER', 3:'B-ORG', 4:'I-ORG', 5: 'B-LOC', 6:'I-LOC', 7:'PAD'}\n",
        "label2id = {v:k for k,v in id2labels.items()} "
      ],
      "metadata": {
        "id": "OJAdnv3jOfIy"
      },
      "id": "OJAdnv3jOfIy",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.preprocessing.sequence.pad_sequences(wikiann_dataset['train']['ner_tags'], value=7,\n",
        "                                                  maxlen=MAX_LEN,  padding='post')\n",
        "y_test = tf.keras.preprocessing.sequence.pad_sequences(wikiann_dataset['test']['ner_tags'], value=7,\n",
        "                                                       maxlen=MAX_LEN,  padding='post')"
      ],
      "metadata": {
        "id": "VAAwr9zrOfj1"
      },
      "id": "VAAwr9zrOfj1",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Модель с 3-мя BiLSTM слоями\n",
        "\n"
      ],
      "metadata": {
        "id": "N9B7PpkIPaCa"
      },
      "id": "N9B7PpkIPaCa"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs)\n",
        "\n",
        "lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embeddings)\n",
        "lstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(lstm_1)\n",
        "lstm_3 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(lstm_2)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(lstm_3)\n",
        "\n",
        "bilstm_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "bilstm_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t39aFIpLOvaj"
      },
      "id": "t39aFIpLOvaj",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm_model.fit(X, y, \n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128,\n",
        "         epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOTR37Z2PXH4",
        "outputId": "7f41153b-6845-4149-947f-4ee07ca2f6ae"
      },
      "id": "bOTR37Z2PXH4",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 38s 153ms/step - loss: 0.2424 - accuracy: 0.9318 - val_loss: 0.1502 - val_accuracy: 0.9523\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 18s 115ms/step - loss: 0.1267 - accuracy: 0.9595 - val_loss: 0.1079 - val_accuracy: 0.9649\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 18s 115ms/step - loss: 0.0763 - accuracy: 0.9757 - val_loss: 0.0662 - val_accuracy: 0.9791\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 18s 115ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 0.0582 - val_accuracy: 0.9824\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 18s 116ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0652 - val_accuracy: 0.9810\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44f1115950>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = bilstm_model.predict(X_test).argmax(2)"
      ],
      "metadata": {
        "id": "kmMZ2D0pPj4u"
      },
      "id": "kmMZ2D0pPj4u",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
        "                                                                     target_names=list(id2labels.values()),\n",
        "                                                                     zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNLyN23UPlt0",
        "outputId": "68028212-0b74-4abd-ed6c-cb381e80e517"
      },
      "id": "fNLyN23UPlt0",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.93      0.94     40480\n",
            "       B-PER       0.95      0.75      0.84      3542\n",
            "       I-PER       0.95      0.73      0.83      7544\n",
            "       B-ORG       0.71      0.69      0.70      4074\n",
            "       I-ORG       0.83      0.78      0.80      8008\n",
            "       B-LOC       0.60      0.80      0.68      4560\n",
            "       I-LOC       0.48      0.79      0.60      3060\n",
            "         PAD       1.00      1.00      1.00    468732\n",
            "\n",
            "    accuracy                           0.98    540000\n",
            "   macro avg       0.81      0.81      0.80    540000\n",
            "weighted avg       0.98      0.98      0.98    540000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Модель с 3-мя BiGRU слоями"
      ],
      "metadata": {
        "id": "8FxPidc2P2p7"
      },
      "id": "8FxPidc2P2p7"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs)\n",
        "\n",
        "gru_1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(embeddings)\n",
        "gru_2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(gru_1)\n",
        "gru_3 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(gru_2)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(gru_3)\n",
        "\n",
        "bigru_model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "bigru_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Yx-N8bN_Vh6z"
      },
      "id": "Yx-N8bN_Vh6z",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigru_model.fit(X, y, \n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128,\n",
        "          epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Uuqw1PmXtJX",
        "outputId": "1505bac7-5bd1-4879-a759-4c8f9a963285"
      },
      "id": "1Uuqw1PmXtJX",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "157/157 [==============================] - 30s 125ms/step - loss: 0.2293 - accuracy: 0.9344 - val_loss: 0.1051 - val_accuracy: 0.9661\n",
            "Epoch 2/5\n",
            "157/157 [==============================] - 17s 106ms/step - loss: 0.0601 - accuracy: 0.9809 - val_loss: 0.0497 - val_accuracy: 0.9843\n",
            "Epoch 3/5\n",
            "157/157 [==============================] - 17s 109ms/step - loss: 0.0190 - accuracy: 0.9942 - val_loss: 0.0497 - val_accuracy: 0.9853\n",
            "Epoch 4/5\n",
            "157/157 [==============================] - 17s 110ms/step - loss: 0.0089 - accuracy: 0.9974 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
            "Epoch 5/5\n",
            "157/157 [==============================] - 17s 106ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0596 - val_accuracy: 0.9855\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f444d1a6450>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = bigru_model.predict(X_test).argmax(2)"
      ],
      "metadata": {
        "id": "mrgNtxM6XynX"
      },
      "id": "mrgNtxM6XynX",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
        "                                                                     target_names=list(id2labels.values()),\n",
        "                                                                     zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2jvMhB_X4az",
        "outputId": "56e8cd44-4b11-41e8-c3dd-5bd67cc29107"
      },
      "id": "S2jvMhB_X4az",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.94      0.95      0.95     40480\n",
            "       B-PER       0.88      0.87      0.88      3542\n",
            "       I-PER       0.91      0.90      0.90      7544\n",
            "       B-ORG       0.69      0.73      0.71      4074\n",
            "       I-ORG       0.85      0.79      0.82      8008\n",
            "       B-LOC       0.70      0.80      0.75      4560\n",
            "       I-LOC       0.90      0.69      0.78      3060\n",
            "         PAD       1.00      1.00      1.00    468732\n",
            "\n",
            "    accuracy                           0.99    540000\n",
            "   macro avg       0.86      0.84      0.85    540000\n",
            "weighted avg       0.99      0.99      0.99    540000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Анализ результатов, проверка модели на своих примерах\n",
        "\n",
        "Если сравнивать модели по метрикам, то их качество практически не отличается: значение f-меры для модели на основе BiLSTM равно 0.98, а для модели BiGRU — 0.99. \n",
        "<br>\n",
        "Наименьшее значение f-меры для BiLSTM модели соответствует классу I-LOC (f1 = 0.60). Модель BiGRU хуже всего предсказывает класс B-ORG (f1 = 0.71)."
      ],
      "metadata": {
        "id": "wEQzYoYwBbcH"
      },
      "id": "wEQzYoYwBbcH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим работу моделей на нескольких реальных примерах:"
      ],
      "metadata": {
        "id": "R58BTI_7CiA3"
      },
      "id": "R58BTI_7CiA3"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text, word2id):\n",
        "    # токенизирует и переводит в индексы\n",
        "    tokens = re.findall('\\w+|[^\\w\\s]+', text)\n",
        "    ids = [word2id.get(token.lower(), 1) for token in tokens]\n",
        "    return tokens, ids\n",
        "\n",
        "def pred2tags(pred, id2label, length):\n",
        "    # декодирует индексы в части речи\n",
        "    # length нужно чтобы откидывать паддинги или некорректные предсказания\n",
        "    pred = pred.argmax(2)[0, :length]\n",
        "    labels = [id2label[l] for l in pred]\n",
        "    return labels\n",
        "\n",
        "def label_seq(text, word2id, id2label, max_len, model):\n",
        "    tokens, ids = tokenize(text, word2id)\n",
        "    pred = model.predict(tf.keras.preprocessing.sequence.pad_sequences([ids], \n",
        "                                                                       maxlen=max_len, \n",
        "                                                                       padding='post'))\n",
        "    labels = pred2tags(pred, id2label, len(ids))\n",
        "    \n",
        "    return list(zip(tokens, labels))"
      ],
      "metadata": {
        "id": "fWBUfaTMB7el"
      },
      "id": "fWBUfaTMB7el",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('Маша ездила навестить своих родственников в Татарстан.', word2id, id2labels, MAX_LEN, bilstm_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqgwVaa5DbYv",
        "outputId": "de7a3801-5d9b-4790-907e-b72ef91c5a6f"
      },
      "id": "YqgwVaa5DbYv",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Маша', 'B-ORG'),\n",
              " ('ездила', 'I-ORG'),\n",
              " ('навестить', 'I-ORG'),\n",
              " ('своих', 'O'),\n",
              " ('родственников', 'O'),\n",
              " ('в', 'O'),\n",
              " ('Татарстан', 'B-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('Маша ездила навестить своих родственников в Татарстан.', word2id, id2labels, MAX_LEN, bigru_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nfmHsJQHuiE",
        "outputId": "0e280eb4-4544-4d4e-8938-d7f4186eb065"
      },
      "id": "2nfmHsJQHuiE",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Маша', 'B-PER'),\n",
              " ('ездила', 'I-PER'),\n",
              " ('навестить', 'O'),\n",
              " ('своих', 'O'),\n",
              " ('родственников', 'O'),\n",
              " ('в', 'O'),\n",
              " ('Татарстан', 'B-LOC'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что даже на достаточно простых примерах модели могут делать грубые ошибки. Так, модель на основе BiLSTM неверно присвоила именованной сущности \"Маша\" тег B-ORG. При этом модель на основе BiGRU присвоила слову верный тег (B-PER). "
      ],
      "metadata": {
        "id": "ZfQarjyGJ_nl"
      },
      "id": "ZfQarjyGJ_nl"
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('В городе Симферополь закрылся аэропорт.', word2id, id2labels, MAX_LEN, bilstm_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWUZimkbIC2T",
        "outputId": "ed5e63c2-d143-445d-e32c-706357179600"
      },
      "id": "YWUZimkbIC2T",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('В', 'O'),\n",
              " ('городе', 'O'),\n",
              " ('Симферополь', 'B-ORG'),\n",
              " ('закрылся', 'I-ORG'),\n",
              " ('аэропорт', 'I-ORG'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('В городе Симферополь закрылся аэропорт.', word2id, id2labels, MAX_LEN, bigru_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLMkJmQ4Ia3W",
        "outputId": "a7b5cf37-7072-437a-c2e5-f397ef190ca5"
      },
      "id": "HLMkJmQ4Ia3W",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('В', 'O'),\n",
              " ('городе', 'O'),\n",
              " ('Симферополь', 'B-LOC'),\n",
              " ('закрылся', 'I-ORG'),\n",
              " ('аэропорт', 'I-ORG'),\n",
              " ('.', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В примере выше модель на основе BiLSTM снова уступила BiGRU, присвоив неверный тег именованной сущности \"Симферополь\" (ORG вместо LOC)."
      ],
      "metadata": {
        "id": "zroOQ7VbLIaw"
      },
      "id": "zroOQ7VbLIaw"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Copy_of_hw8_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}