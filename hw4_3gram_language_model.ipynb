{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00fad453"
   },
   "source": [
    "# Домашнее задание № 4. Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d056af4"
   },
   "source": [
    "## Задание 1 (8 баллов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1f532a8"
   },
   "source": [
    "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "de743d1d"
   },
   "source": [
    "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
    "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели. \n",
    "Можно использовать данные из семинара или любые другие (сопоставимые или большие по объему). Перплексию расчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
    "\n",
    "\n",
    "Подсказки:  \n",
    "    - нужно будет добавить еще один тэг <start>  \n",
    "    - еще одна матрица не нужна, можно по строкам хранить биграмы, а по колонкам униграммы  \n",
    "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d078056d",
    "outputId": "4c120a4b-3cd4-4c03-d701-82e07db6c3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# все импорты тут \n",
    "\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "6afcef88"
   },
   "outputs": [],
   "source": [
    "# считываем корпус новостей Lenta\n",
    "news = open('lenta.txt').read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "O8faSEQVYyn1"
   },
   "outputs": [],
   "source": [
    "# удаляем пунктуацию, токенизируем и приводим к нижнему регистру\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "IGoEhdNsY49e"
   },
   "outputs": [],
   "source": [
    "# применим нормализацию к корпусу\n",
    "norm_news = normalize(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "SRwoBvFsZAL9"
   },
   "outputs": [],
   "source": [
    "# создадим частотный словарь \n",
    "vocab_news = Counter(norm_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "c2TfMN6fZMq0"
   },
   "outputs": [],
   "source": [
    "# переведем абсолютные частоты в вероятности, разделив кол-во употреблений слова на общее число слов в корпусе\n",
    "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "iqJpkg6RArog"
   },
   "outputs": [],
   "source": [
    "# ищем кол-во вхождений каждой n-граммы\n",
    "def ngrammer(tokens, n):\n",
    "    ngrams = []\n",
    "    # проходимся по токенам\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "J3i8HUb-at7W"
   },
   "outputs": [],
   "source": [
    "# токенезируем на предложения и добавляем теги вначале и в конце\n",
    "sentences_news = [['<start>','<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news)]\n",
    "\n",
    "# берем отрывок из 10 предложений для расчета перплексии\n",
    "test_sentences = sentences_news[-10:]\n",
    "test_sentences = [' '.join(sent).replace('<start>', '').replace('<end>', '') for sent in test_sentences]\n",
    "\n",
    "# убираем эти предложения из основной выборки\n",
    "sentences_news = sentences_news[:-10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dyop-xxjAxyq"
   },
   "source": [
    "Создадим частотные словари униграм, биграм и триграм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "yEs6S9cuax6D"
   },
   "outputs": [],
   "source": [
    "unigrams_news = Counter()\n",
    "bigrams_news = Counter()\n",
    "trigrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    bigrams_news.update(ngrammer(sentence,2))\n",
    "    trigrams_news.update(ngrammer(sentence, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVKk_ndP-Kcz"
   },
   "source": [
    "Частотный словарь для униграм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mgby4wrGh--Y",
    "outputId": "61f75724-8a4c-48fc-b81a-5765450b9608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start>', 152668),\n",
       " ('<end>', 76334),\n",
       " ('в', 72401),\n",
       " ('и', 33289),\n",
       " ('на', 28432),\n",
       " ('по', 19489),\n",
       " ('что', 17031),\n",
       " ('с', 15918),\n",
       " ('не', 12701),\n",
       " ('из', 7727)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_news.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BousMOvX-RVj"
   },
   "source": [
    "Частотный словарь для биграм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k04EYvxsa45P",
    "outputId": "afb9d63e-edae-4171-fdf8-62f0957d85bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start> <start>', 76344),\n",
       " ('<start> в', 7972),\n",
       " ('<start> по', 6211),\n",
       " ('<start> как', 3738),\n",
       " ('риа новости', 3504),\n",
       " ('по словам', 1971),\n",
       " ('об этом', 1795),\n",
       " ('<start> однако', 1694),\n",
       " ('<start> на', 1643),\n",
       " ('что в', 1624)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_news.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-wfF5EF-W1P"
   },
   "source": [
    "Частотный словарь для триграм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FvN6MPoh6bT",
    "outputId": "4fb4051d-b773-4795-96a9-c65bffb917b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<start> <start> в', 7972),\n",
       " ('<start> <start> по', 6211),\n",
       " ('<start> <start> как', 3738),\n",
       " ('<start> <start> однако', 1694),\n",
       " ('<start> <start> на', 1643),\n",
       " ('<start> <start> об', 1619),\n",
       " ('<start> об этом', 1579),\n",
       " ('<start> <start> он', 1553),\n",
       " ('<start> по словам', 1549),\n",
       " ('сообщает риа новости', 1324)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_news.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWN7PtI0kOBB"
   },
   "source": [
    "# Генерация текста с помощью трехграммной языковой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHuVLkfuA4lI"
   },
   "source": [
    "Матрица вероятностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "Pmd6QylIbQS5"
   },
   "outputs": [],
   "source": [
    "matrix_news = lil_matrix((len(bigrams_news), \n",
    "                   len(unigrams_news)))\n",
    "\n",
    "id2word_news = list(unigrams_news)\n",
    "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
    "\n",
    "id2bigram_news = list(bigrams_news)\n",
    "bigram2id_news = {word:i for i, word in enumerate(id2bigram_news)}\n",
    "\n",
    "for ngram in trigrams_news:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    bigram = word1 + ' ' + word2\n",
    "\n",
    "    matrix_news[bigram2id_news[bigram], word2id_news[word3]] =  (trigrams_news[ngram]/\n",
    "                                                                     bigrams_news[bigram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TKrJlPqBCgA"
   },
   "source": [
    "Функция генерации текста на основе трехграммной языковой модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "HnsY7XbZbdFB"
   },
   "outputs": [],
   "source": [
    "def generate(matrix, id2word, id2bigram, bigram2id, n=250, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = bigram2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "        chosen = np.random.choice(list(range(matrix.shape[1])), \n",
    "                                  p=matrix[current_idx].toarray()[0])\n",
    "\n",
    "        text.append(id2word[chosen])\n",
    "        \n",
    "        if id2word[chosen] == '<end>':\n",
    "          current_idx = bigram2id[start]\n",
    "        else:\n",
    "          chunk = id2bigram[current_idx] + ' ' + id2word[chosen]\n",
    "          chunk = ' '.join(chunk.split()[1:])\n",
    "          current_idx = bigram2id[chunk]\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77WCb0vwxjLE"
   },
   "source": [
    "Сгенерируем несколько текстов с помощью модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bExAZ0crbfid",
    "outputId": "366ac3ce-e14c-40ab-e126-fd28346a127e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "в проекте москва-сити-2000 \n",
      " в результате удара грузовик перевернулся раздавив еще два дня будет опрошено 80 тысяч человек \n",
      " напомним что 10 апреля в москве \n",
      " помимо взаимодействия с администрацией яковлева по блоку отечество вся россия правительство россии выразило заинтересованность в заводах daewoo проявила также и его состояние как тяжелое \n",
      " договор по про \n",
      " многих из них не намерены отказываться от собственной программы реформ по ряду одномандатных округов ни у россиян являются собственностью великобритании сегодня в час больше у чем у всех прочих проектов из средств приморского военного совхоза речинский надеясь что никто не пострадал \n",
      " из 74 тысяч первично зарегистрированных в территориальных водах 10 танкеров подозреваемых в участии в бандформированиях в гудермесе по подозрению в причастности к совершенному накануне нападению на колонну подмосковного омона понесли конкретные лица которые занимались их переправкой за пределы взлетно-посадочной полосы получили незначительные повреждения и взорвалась \n",
      " по словам ричардсона несмотря на то что американские налогоплательщики произведут в этом доме подпольный цех поизготовлению самодельных взрывных устройств в четверг 27 января в московской гостинице националь было объявлено что 31 декабря текущего года \n",
      " в среду the seattle times согласно данным распространенным в нью-йорке хотя твердых доказательств их причастности к похищению шпигуна ряда высокопоставленных чиновников при масхадове \n",
      " по мнению юристов адвокату жириновского трудно будет отвести от лидера на 3-4 очка туринский ювентус чемпион италии \n",
      " известно что в течение последнего месяца \n",
      " тайсон отправил соперника в нокдаун уже на пятой минуте \n",
      " и можно предполагать что выборы мэра и вице-мэра москвы вяче c лавом глазычевым\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2word_news, id2bigram_news, bigram2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h82HDJG0xohs",
    "outputId": "e5fc75ae-476e-4525-a276-264244e1a189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "по его словам была проверена информация ряда сми о том что правительство россии внесло изменения в закон о выборах в грузинский парламент приняло участие в судьбе ветерана второй мировой войны и мира iwpr \n",
      " в дни трагедии число доноров перевалило за миллиард долларов \n",
      " департамент рекомендует гражданам российской федерации василий стародубцев в понедельник о совместном приобретении терпящей бедствие daewoo motor сообщает немецкая handelsblatt \n",
      " из мировой практики \n",
      " причины экономический кризис падение количества авиаперевозок увеличение цены авиатоплива и строгость новых европейских требований по вэбовкам 7 от юридических лиц с общей суммой требований в городских условиях сообщила телекомпания нтв сообщила что ей очень нравится походка владимира путина за содействие поездке делегации се в чечню вылетают эксперты совета европы передает интерфакс \n",
      " момент когда машина ехала по улице гурьянова 19 эквивалентен взрыву 300-400 кг в либо большого объема работы прокуратура москвы расследующая уголовное дело труженики парижских публичных домов российский оператор дальней связи ростелеком и оао газпром и газпромбанк подписали соглашение о поставках в грузию \n",
      " югославские власти требуют также отменить все распоряжения руководителя миссии оон в бюджет достигла 500 миллиардов рублей будут распространяться также на обеспечение северного завоза будут теперь предоставляться субъектам через органы казначейства для их планов так как оно означает начало консолидации демократических сил позволит провести собрание горожан на котором подводили итоги диверсионной деятельности своих формирований \n",
      " вертолеты уже доставлены медикаменты и необходимая для дальнейшей перепродажи министерство иностранных дел россии \n",
      " между тем право участвовать в президентских выборах ее сторонники считают что в случае обнаружения его знаменитых родственников back orifice\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2word_news, id2bigram_news, bigram2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rbT4S-kx31j",
    "outputId": "8ea1dbdc-b1ba-4b7d-c90b-6a7405eb7ca0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего в здании городской администрации владимир пирожков были членами предвыборного штаба союза правых сил представитель фракции кпрф воздержались от голосования \n",
      " прибывшие на место пожарные \n",
      " осужденный моу цыжон стал одним из основных тем обсуждения на заседании отмечалось что вдействующем законодательстве россии не подтверждают что у чеченской стороны \n",
      " в течение часа но потом когда люди возвращались с экскурсии занесло на скользкой дороге бортовой компьютер сбавляет мощность идущую на оформление букетов и икебан \n",
      " министр также проинформировал о намеченном на 24 часа в основном сводится к непрерывному конвертированию текстовой новостной информации в течение часа летать кругами чтобы выработать излишки топлива \n",
      " участники встречи заняли бескомпромиссную позицию в новом доме расположенном около местной больницы он начал раздавать автографы кто-то стукнул его по почте \n",
      " принц уэльский получает доходы от владения герцогством корнуолл в размере 50 миллионов долларов в течение двух часов детей удерживали в горной части чечни группы боевиков выйти из блокированного войсками высокогорного селения хал-килой в 15 миллиардов долларов \n",
      " тем кто проходит здесь службу молодым офицером милиции \n",
      " таким образом из обслуживающего персонала и модернизацию наземной авиационной инфраструктуры \n",
      " одновременно сообщается об избрании михаила касьянова с и о \n",
      " минобороны рф \n",
      " на эти деньги уже покинули россию и украину \n",
      " венгерские власти зафиксировали 2000-кратную по сравнению с действующими ранее расчетами по налогам и сборам злоумышленники объявляли своих родственников ищут контакты с учреждениями на оккупированной территории считаются незаконными \n",
      " к началу переговоров \n",
      " по его мнению цик нынешниевыборы были беспрецедентными по своей значимости природе и распространенности выявленные ошибки незначительно\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_news, id2word_news, id2bigram_news, bigram2id_news).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9waF_kMibiuL"
   },
   "source": [
    "## Перплексия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gs_RJNtN-qvE"
   },
   "source": [
    "Функция для расчета перплексии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "BrILEjcoblZN"
   },
   "outputs": [],
   "source": [
    "def perplexity(probas):\n",
    "    p = np.exp(np.sum(probas))\n",
    "    N = len(probas)\n",
    "    \n",
    "    return p**(-1/N) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFCG2BvmbvIV"
   },
   "source": [
    "\n",
    "Посчитаем усредненную перплексию для 10 предложений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "lBu9b89g6dcU"
   },
   "outputs": [],
   "source": [
    "probas_news = Counter({word:c/len(norm_news) for word, c in vocab_news.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "bHhteDhPbm7B"
   },
   "outputs": [],
   "source": [
    "probs = []\n",
    "\n",
    "for sent in test_sentences:\n",
    "  prob = []\n",
    "  for word in normalize(sent):\n",
    "    if word in probas_news:\n",
    "        prob.append(np.log(probas_news[word]))\n",
    "    else:\n",
    "        prob.append(np.log(1/len(norm_news)))\n",
    "  probs.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "05UAL2cibssa"
   },
   "outputs": [],
   "source": [
    "prplxs = [] # тут хранятся значения перплексий для каждого из 10 предложений\n",
    "for prob in probs:\n",
    "  p = perplexity(prob)\n",
    "  prplxs.append(p)\n",
    "\n",
    "# усредненное значение перплексии для отрывка текста из 10 предложений\n",
    "avg_perplexity = np.mean(prplxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VNPIrfNQ7SW_",
    "outputId": "cd3720a4-d24d-40a9-9097-f97319b4afd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11794.537887591401"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAFv48FDb07n"
   },
   "source": [
    "Сравнение с языковой моделью на основе 3-грамм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "c2auTfHyb45v"
   },
   "outputs": [],
   "source": [
    "probs_model = []\n",
    "\n",
    "for sent in test_sentences:\n",
    "  prob = []\n",
    "  for ngram in ngrammer(['<start>', '<start>'] + normalize(sent) + ['<end>'], 3):\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    bigram = word1 + ' ' + word2\n",
    "\n",
    "    if bigram in bigrams_news and ngram in trigrams_news:\n",
    "        prob.append(np.log(trigrams_news[ngram]/bigrams_news[bigram]))\n",
    "    else:\n",
    "        prob.append(np.log(0.00001))\n",
    "    probs_model.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "jze7XK-pcJyp"
   },
   "outputs": [],
   "source": [
    "prplxs_model = [] # тут хранятся значения перплексий для каждого из 10 предложений\n",
    "for prob in probs_model:\n",
    "  p = perplexity(prob)\n",
    "  prplxs_model.append(p)\n",
    "\n",
    "# усредненное значение перплексии для отрывка текста из 10 предложений\n",
    "avg_perplexity_model = np.mean(prplxs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yKLo-PRl9gU1",
    "outputId": "70eae6f0-101c-41c3-a8c1-8f17a9669246"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13319.775135275695"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_perplexity_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLgKDR6S_6t0"
   },
   "source": [
    "Возможно, в рассчете перплексии есть ошибка, так как значение перплексии для языковой модели получилось выше, чем для корпуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e0a8dd5"
   },
   "source": [
    "## Задание № 2* (2 балла). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b36c44b"
   },
   "source": [
    "Прочитайте главу про языковое моделирование в книге Журафски и Мартина - https://web.stanford.edu/~jurafsky/slp3/3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d9b1bd8"
   },
   "source": [
    "Развернуто (в пределах 1000 знаков) ответьте на вопросы (по-русски):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0c2cf844"
   },
   "source": [
    "**1. Что можно делать с проблемой несловарных слов? В семинаре мы просто использовали какое-то маленькое значение вероятности, а какие есть другие способы?**\n",
    "\n",
    "В статье описаны два способа обработки несловарных слов:\n",
    "\n",
    "1) Выбрать фиксированный словарь; на этапе нормализации преобразовать все несловарные слова (которых нет в фиксированном словаре) в токен неизвестного слова с помощью метки UNK (от англ. unknown word token). Рассчитать вероятности для UNK как для других слов в обучающей выборке. \n",
    "<br>\n",
    "2) Неявно создать словарь на основе всей обучающей выборки, заменив малочастнотные слова на UNK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1d1c152"
   },
   "source": [
    "**2. Что такое сглаживание (smoothing)?**\n",
    "\n",
    "Сглаживание используется для избежания занулений вероятностей языковой моделью для слов, которые есть в словаре, но появились в неизвестном контексте. Для обработки таких слов мы отделяем небольшую часть значения вероятности у более частотных слов и присваиваем эту часть вместо нулевой вероятности. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
