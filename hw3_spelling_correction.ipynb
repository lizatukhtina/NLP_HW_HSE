{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYis-EI8prva"
      },
      "source": [
        "# Домашнее задание № 3. Исправление опечаток"
      ],
      "id": "YYis-EI8prva"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7933lFCBprvl"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "\n",
        "import textdistance\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
      ],
      "id": "7933lFCBprvl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5VHMTjmprvr"
      },
      "source": [
        "### Данные\n",
        "Корпус из Wikipedia в качестве словаря правильных слов"
      ],
      "id": "D5VHMTjmprvr"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "d8BzCo5bprvt"
      },
      "outputs": [],
      "source": [
        "# считываем корпус\n",
        "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
        "# создаем частотный словарь\n",
        "WORDS = Counter(re.findall('\\w+', corpus.lower()))"
      ],
      "id": "d8BzCo5bprvt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnFs7ghnprvu"
      },
      "source": [
        "Корпус с соревнования по исправлению опечаток [Dialog Evaluation 2016](http://www.dialog-21.ru/evaluation/2016/spelling_correction/) для оценки качества алгоритма исправления ошибок"
      ],
      "id": "fnFs7ghnprvu"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ivkqj2MLprvv"
      },
      "outputs": [],
      "source": [
        "# предложения с ошибками\n",
        "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
        "# предложения без ошибок\n",
        "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
      ],
      "id": "Ivkqj2MLprvv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUNH3tJBprvw"
      },
      "source": [
        "## 1. Доп. ранжирование по вероятности (3 балла)"
      ],
      "id": "EUNH3tJBprvw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FUnw_sIprvy"
      },
      "source": [
        "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное.\n",
        "\n"
      ],
      "id": "-FUnw_sIprvy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Решение"
      ],
      "metadata": {
        "id": "CICoDrg49h04"
      },
      "id": "CICoDrg49h04"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для поиска наиболее вероятного кандидата будем использовать функцию для рассчета вероятности встретить слово word в словаре WORDS:"
      ],
      "metadata": {
        "id": "9JlOdVPX5okm"
      },
      "id": "9JlOdVPX5okm"
    },
    {
      "cell_type": "code",
      "source": [
        "def P(word, N=sum(WORDS.values())): \n",
        "    \"\"\" Вероятность встретить слово в словаре \"\"\"\n",
        "    \n",
        "    return WORDS[word] / N"
      ],
      "metadata": {
        "id": "dRbXIGlk5kKP"
      },
      "id": "dRbXIGlk5kKP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Единственное изменение, которое потребуется внести в код из семинара — возвращаемое значение метода get_closest_hybrid_match. Вместо списка из кандидатов на исправление будем возвращать только одно слово — для которого наибольшая вероятность встретиться в корпусе"
      ],
      "metadata": {
        "id": "P6SyNAGE6hTr"
      },
      "id": "P6SyNAGE6hTr"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "isvjf3lCprvz"
      },
      "outputs": [],
      "source": [
        "# оригинальный код для методов ниже лежит тут: \n",
        "# https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/spelling/Spellchecking.ipynb\n",
        "\n",
        "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
        "    # Counter можно использовать и с не целыми числами\n",
        "    similarities = Counter()\n",
        "    \n",
        "    for word in lookup:\n",
        "        similarities[word] = metric.normalized_similarity(text, word) \n",
        "    \n",
        "    return similarities.most_common(topn)\n",
        "\n",
        "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
        "\n",
        "word2id = list(vocab.keys())\n",
        "id2word = {i:word for i, word in enumerate(vocab)}\n",
        "\n",
        "\n",
        "vec = CountVectorizer(analyzer='char', ngram_range=(1,3), max_features=1000)\n",
        "X = vec.fit_transform(vocab)\n",
        "\n",
        "def get_closest_match_vec(text, X, vec, topn=20):\n",
        "    v = vec.transform([text])\n",
        "    similarities = cosine_distances(v, X)[0]\n",
        "    topn = similarities.argsort()[:topn] \n",
        "    \n",
        "    return [(id2word[top], similarities[top]) for top in topn]\n",
        "\n",
        "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
        "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
        "    lookup = [cand[0] for cand in candidates]\n",
        "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
        "\n",
        "    # изменяем в исходном коде эту строчку:\n",
        "    # return closest\n",
        "    # из полученных кандидитов выбираем наиболее вероятный вариант\n",
        "    return list(max(closest, key=P))[0] # вытаскиваем только само слово"
      ],
      "id": "isvjf3lCprvz"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iewFdghEprv2",
        "outputId": "e809edd6-a816-404e-8325-6215dc5a7d0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'медвежонок'"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "get_closest_hybrid_match('метвежёнок', X, vec)"
      ],
      "id": "iewFdghEprv2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_cYWqMMprv4"
      },
      "source": [
        "## 2.  Symspell (5 баллов)"
      ],
      "id": "p_cYWqMMprv4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4asBdptprv5"
      },
      "source": [
        "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Там к словам применяется только одна операция - удаление символа. Описание алгоритма по шагам:\n",
        "\n",
        "1) Составляется словарь правильных слов  \n",
        "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово   \n",
        "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
        "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
        "\n",
        "\n",
        "Оцените качество полученного алгоритма теми же тремя метриками."
      ],
      "id": "B4asBdptprv5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_r2CFNnprv8"
      },
      "source": [
        "### Реализация алгоритма SymSpell"
      ],
      "id": "O_r2CFNnprv8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKBc7Ranprv9"
      },
      "source": [
        "Отредактируем алгоритм [Норвига](https://norvig.com/spell-correct.html), оставив только операцию удаления"
      ],
      "id": "WKBc7Ranprv9"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Z4mlzlquprv-"
      },
      "outputs": [],
      "source": [
        "def get_deletes1(word):\n",
        "    \"\"\" Поочередно удаляем из слова 1 букву \"\"\"\n",
        "    \n",
        "    letters    = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
        "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "    \n",
        "    return set(deletes)\n",
        "\n",
        "def get_deletes_vocab():\n",
        "    \"\"\" Создаем словарь удалений \"\"\"\n",
        "    \n",
        "    deletes_vocab = {}\n",
        "    for w in WORDS:\n",
        "        deletes_vocab[w] = get_deletes1(w)\n",
        "    \n",
        "    return deletes_vocab\n",
        "\n",
        "# создаем словарь удалений и сохраняем его как константу\n",
        "VOCAB = get_deletes_vocab()\n",
        "\n",
        "\n",
        "def get_candidates(word): \n",
        "    \"\"\" Генерируем кандидатов на исправление \"\"\"\n",
        "    \n",
        "    candidates = []\n",
        "    # генерируем все варианты удалений для слова\n",
        "    words = get_deletes1(word)\n",
        "    # ищем совпадения в словаре удалений\n",
        "    for key in VOCAB.keys():\n",
        "        if len(words.intersection(VOCAB[key])) > 0:\n",
        "            candidates.append(key)\n",
        "                                \n",
        "    return set(candidates)\n",
        "\n",
        "def make_correction(word): \n",
        "    \"\"\" Находим наиболее вероятное похожее слово \"\"\"\n",
        "    \n",
        "    if word in WORDS:\n",
        "        return word\n",
        "    else:\n",
        "        candidates = get_candidates(word)\n",
        "        if len(candidates) == 1: \n",
        "            return list(candidates)[0]\n",
        "        elif len(candidates) > 1:\n",
        "            return list(max(get_candidates(word), key=P))[0]\n",
        "        # если исправления не найдены, возвращаем исходное слово\n",
        "        else:\n",
        "            return word\n"
      ],
      "id": "Z4mlzlquprv-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lGuU7eHprwB"
      },
      "source": [
        "Структура словаря VOCAB: ключ — правильное слово, значение — множество всех удалений (выбрасывается только одна буква)"
      ],
      "id": "1lGuU7eHprwB"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLSoRP0SprwD",
        "outputId": "f05cb5d4-2c8f-400e-c86e-3ea3fa229124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'едвежонок',\n",
              " 'мдвежонок',\n",
              " 'мевежонок',\n",
              " 'медвежнок',\n",
              " 'медвежонк',\n",
              " 'медвежоно',\n",
              " 'медвежоок',\n",
              " 'медвеонок',\n",
              " 'медвжонок',\n",
              " 'медежонок'}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "VOCAB['медвежонок']"
      ],
      "id": "ZLSoRP0SprwD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6CnladKprwH"
      },
      "source": [
        "Попробуем исправить ошибки"
      ],
      "id": "M6CnladKprwH"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QUTmxcFIprwJ",
        "outputId": "150c5234-c038-4483-e603-990e58a2745f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'медвежонок'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "make_correction('медвежёнок')"
      ],
      "id": "QUTmxcFIprwJ"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RuUI2VftprwK",
        "outputId": "42319d44-9861-4050-88a7-34b25b5f40ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'здравствуйте'"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "make_correction('здрафствуйте')"
      ],
      "id": "RuUI2VftprwK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj4vAfQtprwM"
      },
      "source": [
        "Алгоритм не сработает, если ошибка в слове заключается в пропуске буквы"
      ],
      "id": "dj4vAfQtprwM"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6zYWKAIPprwN",
        "outputId": "05da9a41-d7a9-4dc5-aa7c-24b714d8ca5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'здраствуйте'"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "make_correction('здраствуйте')"
      ],
      "id": "6zYWKAIPprwN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihJ-82XjprwP"
      },
      "source": [
        "### Оценка качества алгоритма"
      ],
      "id": "ihJ-82XjprwP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LaItWBtprwQ"
      },
      "source": [
        "Оценим качество алгоритма, прогнав его на корпусе с соревнования по исправлению опечаток"
      ],
      "id": "0LaItWBtprwQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6A-MXeOprwR"
      },
      "source": [
        "Метрики для оценки качества алгоритма:\n",
        "\n",
        "— процент правильных слов;  \n",
        "— процент исправленных ошибок  \n",
        "— процент ошибочно исправленных правильных слов"
      ],
      "id": "f6A-MXeOprwR"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oINzuBKZprwS"
      },
      "outputs": [],
      "source": [
        "# код для рассчета метрик взят отсюда\n",
        "# https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/spelling/Spellchecking.ipynb\n",
        "\n",
        "# напишем функцию, которая будет сопоставлять слова в правильном и ошибочном варианте\n",
        "# разобьем предложение по пробелам и удалим пунктуацию на границах слов\n",
        "def align_words(sent_1, sent_2):\n",
        "    tokens_1 = sent_1.lower().split()\n",
        "    tokens_2 = sent_2.lower().split()\n",
        "    \n",
        "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
        "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
        "    \n",
        "    tokens_1 = [token for token in tokens_1 if token]\n",
        "    tokens_2 = [token for token in tokens_2 if token]\n",
        "    \n",
        "    assert len(tokens_1) == len(tokens_2)\n",
        "    \n",
        "    return list(zip(tokens_1, tokens_2))"
      ],
      "id": "oINzuBKZprwS"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXsaHW8XprwT",
        "outputId": "bc25b130-dc26-4ab6-a726-65c5b1a91572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "total_mistaken = 0\n",
        "mistaken_fixed = 0\n",
        "\n",
        "total_correct = 0\n",
        "correct_broken = 0\n",
        "\n",
        "cashed = {}\n",
        "for i in range(len(true)):\n",
        "    word_pairs = align_words(true[i], bad[i])\n",
        "    for pair in word_pairs:\n",
        "        # чтобы два раза не исправлять одно и тоже слово - закешируем его\n",
        "        # перед тем как считать исправление проверим нет ли его в кеше\n",
        "        \n",
        "        predicted = cashed.get(pair[1], make_correction(pair[1]))\n",
        "        cashed[pair[1]] = predicted\n",
        "        \n",
        "        \n",
        "        if predicted == pair[0]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "        \n",
        "        if pair[0] == pair[1]:\n",
        "            total_correct += 1\n",
        "            if pair[0] !=  predicted:\n",
        "                correct_broken += 1\n",
        "        else:\n",
        "            total_mistaken += 1\n",
        "            if pair[0] == predicted:\n",
        "                mistaken_fixed += 1\n",
        "        \n",
        "    if not i % 100:\n",
        "        print(i)"
      ],
      "id": "DXsaHW8XprwT"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN3WzLhIprwU",
        "outputId": "442f0ede-242d-4b3d-c756-13b56fd09fc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8471235617808904\n",
            "0.13043478260869565\n",
            "0.04685884920179166\n"
          ]
        }
      ],
      "source": [
        "print(correct/total)\n",
        "print(mistaken_fixed/total_mistaken)\n",
        "print(correct_broken/total_correct)"
      ],
      "id": "nN3WzLhIprwU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88uVHoMJprwV"
      },
      "source": [
        "### Вывод\n",
        "\n",
        "Алгоритм SymSpell позволяет исправлять определенные типы ошибок, однако предложенная в данной тетрадке реализация работает хуже, чем алгоритм Норвига, реализованный на [семинаре](https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/spelling/Spellchecking.ipynb). Возможно, оптимизация алгоритма и добавление дополнительной операции удаления позволит улучшить качество SymSpell.\n",
        "\n",
        "Процент исправленных ошибок для SymSpell (с одной операцией удаления): 13%\n",
        "\n",
        "Процент исправленных ошибок алгоритмом Норвига на этом же корпусе: 51%"
      ],
      "id": "88uVHoMJprwV"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "h3_ spelling_correction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}